{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4964d5f0",
   "metadata": {},
   "source": [
    "# Python, NumPy and Vectorization\n",
    "\n",
    "- [&nbsp;&nbsp;1. Useful References](#toc_40015_1.)\n",
    "- [&nbsp;&nbsp;2. Vector Creation](#toc_40015_2.)\n",
    "- [&nbsp;&nbsp;3. Operations on Vectors](#toc_40015_3.)\n",
    "- [&nbsp;&nbsp;4. Matrices](#toc_40015_4.)\n",
    "- [&nbsp;&nbsp;4.1 Matrix Creation](#toc_40015_4.1)\n",
    "- [&nbsp;&nbsp;4.2 Operations on Matrices](#toc_40015_4.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bf18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # it is an unofficial standard to use np for numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e94c9",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_1.\"></a>\n",
    "# 1. Useful References\n",
    "- NumPy Documentation including a basic introduction: [NumPy.org](https://NumPy.org/doc/stable/)\n",
    "- A challenging feature topic: [NumPy Broadcasting](https://NumPy.org/doc/stable/user/basics.broadcasting.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4376",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_2.\"></a>\n",
    "# 2. Vector Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6aff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.zeros(4) :   a = [0. 0. 0. 0.], a shape = (4,), a data type = float64\n",
      "np.zeros(4,) :  a = [0. 0. 0. 0.], a shape = (4,), a data type = float64\n",
      "np.random.random_sample(4): a = [0.61522663 0.5584437  0.33138742 0.02319909], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# NumPy routines which allocate memory and fill arrays with value\n",
    "a = np.zeros(4);                print(f\"np.zeros(4) :   a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.zeros((4,));             print(f\"np.zeros(4,) :  a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.random.random_sample(4); print(f\"np.random.random_sample(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac70fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.arange(4.):     a = [0. 1. 2. 3.], a shape = (4,), a data type = float64\n",
      "np.random.rand(4): a = [0.73541734 0.04764452 0.91099006 0.31536053], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# NumPy routines which allocate memory and fill arrays with value but do not accept shape as input argument\n",
    "a = np.arange(4.);              print(f\"np.arange(4.):     a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.random.rand(4);          print(f\"np.random.rand(4): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ef068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.array([5,4,3,2]):  a = [5 4 3 2],     a shape = (4,), a data type = int64\n",
      "np.array([5.,4,3,2]): a = [5. 4. 3. 2.], a shape = (4,), a data type = float64\n"
     ]
    }
   ],
   "source": [
    "# NumPy routines which allocate memory and fill with user specified values\n",
    "a = np.array([5,4,3,2]);  print(f\"np.array([5,4,3,2]):  a = {a},     a shape = {a.shape}, a data type = {a.dtype}\")\n",
    "a = np.array([5.,4,3,2]); print(f\"np.array([5.,4,3,2]): a = {a}, a shape = {a.shape}, a data type = {a.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8bdc16",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.\"></a>\n",
    "# 3. Operations on Vectors\n",
    "Let's explore some operations using vectors.\n",
    "<a name=\"toc_40015_3.4.1\"></a>\n",
    "## 3.1 Indexing\n",
    "Elements of vectors can be accessed via indexing and slicing. NumPy provides a very complete set of indexing and slicing capabilities. We will explore only the basics needed for the course here. Reference [Slicing and Indexing](https://NumPy.org/doc/stable/reference/arrays.indexing.html) for more details.  \n",
    "**Indexing** means referring to *an element* of an array by its position within the array.  \n",
    "**Slicing** means getting a *subset* of elements from an array based on their indices.  \n",
    "NumPy starts indexing at zero so the 3rd element of an vector $\\mathbf{a}$ is `a[2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457511c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "a[2].shape: () a[2]  = 2, Accessing an element returns a scalar\n",
      "a[-1] = 9\n",
      "The error message you'll see is:\n",
      "index 10 is out of bounds for axis 0 with size 10\n"
     ]
    }
   ],
   "source": [
    "#vector indexing operations on 1-D vectors\n",
    "a = np.arange(10)\n",
    "print(a)\n",
    "\n",
    "#access an element\n",
    "print(f\"a[2].shape: {a[2].shape} a[2]  = {a[2]}, Accessing an element returns a scalar\")\n",
    "\n",
    "# access the last element, negative indexes count from the end\n",
    "print(f\"a[-1] = {a[-1]}\")\n",
    "\n",
    "#indexs must be within the range of the vector or they will produce and error\n",
    "try:\n",
    "    c = a[10]\n",
    "except Exception as e:\n",
    "    print(\"The error message you'll see is:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2280e26",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.2\"></a>\n",
    "## 3.2 Slicing\n",
    "Slicing creates an array of indices using a set of three values (`start:stop:step`). A subset of values is also valid. Its use is best explained by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1311e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a         = [0 1 2 3 4 5 6 7 8 9]\n",
      "a[2:7:1] =  [2 3 4 5 6]\n",
      "a[2:7:2] =  [2 4 6]\n",
      "a[3:]    =  [3 4 5 6 7 8 9]\n",
      "a[:3]    =  [0 1 2]\n",
      "a[:]     =  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#vector slicing operations\n",
    "a = np.arange(10)\n",
    "print(f\"a         = {a}\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step)\n",
    "c = a[2:7:1];     print(\"a[2:7:1] = \", c)\n",
    "\n",
    "# access 3 elements separated by two \n",
    "c = a[2:7:2];     print(\"a[2:7:2] = \", c)\n",
    "\n",
    "# access all elements index 3 and above\n",
    "c = a[3:];        print(\"a[3:]    = \", c)\n",
    "\n",
    "# access all elements below index 3\n",
    "c = a[:3];        print(\"a[:3]    = \", c)\n",
    "\n",
    "# access all elements\n",
    "c = a[:];         print(\"a[:]     = \", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3912efb",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.4.3\"></a>\n",
    "## 3.3 Single vector operations\n",
    "There are a number of useful operations that involve operations on a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7788e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a             : [1 2 3 4]\n",
      "b = -a        : [-1 -2 -3 -4]\n",
      "b = np.sum(a) : 10\n",
      "b = np.mean(a): 2.5\n",
      "b = a**2      : [ 1  4  9 16]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(f\"a             : {a}\")\n",
    "# negate elements of a\n",
    "b = -a \n",
    "print(f\"b = -a        : {b}\")\n",
    "\n",
    "# sum all elements of a, returns a scalar\n",
    "b = np.sum(a) \n",
    "print(f\"b = np.sum(a) : {b}\")\n",
    "\n",
    "b = np.mean(a)\n",
    "print(f\"b = np.mean(a): {b}\")\n",
    "\n",
    "b = a**2\n",
    "print(f\"b = a**2      : {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8018b0",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.4\"></a>\n",
    "## 3.4 Vector Vector element-wise operations\n",
    "Most of the NumPy arithmetic, logical and comparison operations apply to vectors as well. These operators work on an element-by-element basis. For example \n",
    "$$ c_i = a_i + b_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5027b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary operators work element wise: [0 0 6 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([ 1, 2, 3, 4])\n",
    "b = np.array([-1,-2, 3, 4])\n",
    "print(f\"Binary operators work element wise: {a + b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f07403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error message you'll see is:\n",
      "operands could not be broadcast together with shapes (4,) (2,) \n"
     ]
    }
   ],
   "source": [
    "#try a mismatched vector operation\n",
    "c = np.array([1, 2])\n",
    "try:\n",
    "    d = a + c\n",
    "except Exception as e:\n",
    "    print(\"The error message you'll see is:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd7e46",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.5\"></a>\n",
    "## 3.5 Scalar Vector operations\n",
    "Vectors can be 'scaled' by scalar values. A scalar value is just a number. The scalar multiplies all the elements of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4320b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 5 * a : [ 5 10 15 20]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "\n",
    "# multiply a by a scalar\n",
    "b = 5 * a \n",
    "print(f\"b = 5 * a : {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a01626",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.6\"></a>\n",
    "## 3.6 Vector Vector dot product\n",
    "The dot product is a mainstay of Linear Algebra and NumPy. This is an operation used extensively in this course and should be well understood. The dot product is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d799f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dot(a, b): \n",
    "    \"\"\"\n",
    "   Compute the dot product of two vectors\n",
    " \n",
    "    Args:\n",
    "      a (ndarray (n,)):  input vector \n",
    "      b (ndarray (n,)):  input vector with same dimension as a\n",
    "    \n",
    "    Returns:\n",
    "      x (scalar): \n",
    "    \"\"\"\n",
    "    x=0\n",
    "    for i in range(a.shape[0]):\n",
    "        x = x + a[i] * b[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d232143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_dot(a, b) = 24\n"
     ]
    }
   ],
   "source": [
    "# test 1-D\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([-1, 4, 3, 2])\n",
    "print(f\"my_dot(a, b) = {my_dot(a, b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65bee1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy 1-D np.dot(a, b) = 24, np.dot(a, b).shape = () \n",
      "NumPy 1-D np.dot(b, a) = 24, np.dot(a, b).shape = () \n"
     ]
    }
   ],
   "source": [
    "# test 1-D\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([-1, 4, 3, 2])\n",
    "c = np.dot(a, b)\n",
    "print(f\"NumPy 1-D np.dot(a, b) = {c}, np.dot(a, b).shape = {c.shape} \") \n",
    "c = np.dot(b, a)\n",
    "print(f\"NumPy 1-D np.dot(b, a) = {c}, np.dot(a, b).shape = {c.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1651f",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_3.7\"></a>\n",
    "## 3.7 The Need for Speed: vector vs for loop\n",
    "We utilized the NumPy  library because it improves speed memory efficiency. Let's demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d31ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.dot(a, b) =  2501072.5817\n",
      "Vectorized version duration: 3.8548 ms \n",
      "my_dot(a, b) =  2501072.5817\n",
      "loop version duration: 3362.6368 ms \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a = np.random.rand(10000000)  # very large arrays\n",
    "b = np.random.rand(10000000)\n",
    "\n",
    "tic = time.time()  # capture start time\n",
    "c = np.dot(a, b)\n",
    "toc = time.time()  # capture end time\n",
    "\n",
    "print(f\"np.dot(a, b) =  {c:.4f}\")\n",
    "print(f\"Vectorized version duration: {1000*(toc-tic):.4f} ms \")\n",
    "\n",
    "tic = time.time()  # capture start time\n",
    "c = my_dot(a,b)\n",
    "toc = time.time()  # capture end time\n",
    "\n",
    "print(f\"my_dot(a, b) =  {c:.4f}\")\n",
    "print(f\"loop version duration: {1000*(toc-tic):.4f} ms \")\n",
    "\n",
    "del(a);del(b)  #remove these big arrays from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdaae8",
   "metadata": {},
   "source": [
    "<a name=\"toc_12345_3.8\"></a>\n",
    "## 3.8 Vector Vector operations in Course 1\n",
    "Vector Vector operations will appear frequently in course 1. Here is why:\n",
    "- Going forward, our examples will be stored in an array, `X_train` of dimension (m,n). This will be explained more in context, but here it is important to note it is a 2 Dimensional array or matrix (see next section on matrices).\n",
    "- `w` will be a 1-dimensional vector of shape (n,).\n",
    "- we will perform operations by looping through the examples, extracting each example to work on individually by indexing X. For example:`X[i]`\n",
    "- `X[i]` returns a value of shape (n,), a 1-dimensional vector. Consequently, operations involving `X[i]` are often vector-vector.  \n",
    "\n",
    "That is a somewhat lengthy explanation, but aligning and understanding the shapes of your operands is important when performing vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5935876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[1] has shape (1,)\n",
      "w has shape (1,)\n",
      "c has shape ()\n"
     ]
    }
   ],
   "source": [
    "# show common Course 1 example\n",
    "X = np.array([[1],[2],[3],[4]])\n",
    "w = np.array([2])\n",
    "c = np.dot(X[1], w)\n",
    "\n",
    "print(f\"X[1] has shape {X[1].shape}\")\n",
    "print(f\"w has shape {w.shape}\")\n",
    "print(f\"c has shape {c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d5fdf",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_4.\"></a>\n",
    "# 4 Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe173e0",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_4.1\"></a>\n",
    "## 4.1 Matrix Creation\n",
    "The same functions that created 1-D vectors will create 2-D or n-D arrays. Here are some examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "192cfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = (1, 5), a = [[0. 0. 0. 0. 0.]]\n",
      "a shape = (2, 1), a = [[0.]\n",
      " [0.]]\n",
      "a shape = (1, 1), a = [[0.44236513]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((1, 5))                                       \n",
    "print(f\"a shape = {a.shape}, a = {a}\")                     \n",
    "\n",
    "a = np.zeros((2, 1))                                                                   \n",
    "print(f\"a shape = {a.shape}, a = {a}\") \n",
    "\n",
    "a = np.random.random_sample((1, 1))  \n",
    "print(f\"a shape = {a.shape}, a = {a}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b8ff04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a shape = (3, 1), np.array: a = [[5]\n",
      " [4]\n",
      " [3]]\n",
      " a shape = (3, 1), np.array: a = [[5]\n",
      " [4]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "# NumPy routines which allocate memory and fill with user specified values\n",
    "a = np.array([[5], [4], [3]]);   print(f\" a shape = {a.shape}, np.array: a = {a}\")\n",
    "a = np.array([[5],   # One can also\n",
    "              [4],   # separate values\n",
    "              [3]]); #into separate rows\n",
    "print(f\" a shape = {a.shape}, np.array: a = {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e95f5",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_4.2\"></a>\n",
    "## 4.2 Operations on Matrices\n",
    "Let's explore some operations using matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d4b7a",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_4.2.1\"></a>\n",
    "### 4.2.1 Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167de5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape: (3, 2), \n",
      "a= [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "\n",
      "a[2,0].shape:   (), a[2,0] = 4,     type(a[2,0]) = <class 'numpy.int64'> Accessing an element returns a scalar\n",
      "\n",
      "a[2].shape:   (2,), a[2]   = [4 5], type(a[2])   = <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#vector indexing operations on matrices\n",
    "a = np.arange(6).reshape(-1, 2)   #reshape is a convenient way to create matrices\n",
    "print(f\"a.shape: {a.shape}, \\na= {a}\")\n",
    "\n",
    "#access an element\n",
    "print(f\"\\na[2,0].shape:   {a[2, 0].shape}, a[2,0] = {a[2, 0]},     type(a[2,0]) = {type(a[2, 0])} Accessing an element returns a scalar\\n\")\n",
    "\n",
    "#access a row\n",
    "print(f\"a[2].shape:   {a[2].shape}, a[2]   = {a[2]}, type(a[2])   = {type(a[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de66be",
   "metadata": {},
   "source": [
    "**Reshape**  \n",
    "The previous example used [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) to shape the array.  \n",
    "`a = np.arange(6).reshape(-1, 2) `   \n",
    "This line of code first created a *1-D Vector* of six elements. It then reshaped that vector into a *2-D* array using the reshape command. This could have been written:  \n",
    "`a = np.arange(6).reshape(3, 2) `  \n",
    "To arrive at the same 3 row, 2 column array.\n",
    "The -1 argument tells the routine to compute the number of rows given the size of the array and the number of columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd653430",
   "metadata": {},
   "source": [
    "<a name=\"toc_40015_4.2.2\"></a>\n",
    "### 4.2.2 Slicing\n",
    "Slicing creates an array of indices using a set of three values (`start:stop:step`). A subset of values is also valid. Its use is best explained by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e807635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]]\n",
      "a[0, 2:7:1] =  [2 3 4 5 6] ,  a[0, 2:7:1].shape = (5,) a 1-D array\n",
      "a[:, 2:7:1] = \n",
      " [[ 2  3  4  5  6]\n",
      " [12 13 14 15 16]] ,  a[:, 2:7:1].shape = (2, 5) a 2-D array\n",
      "a[:,:] = \n",
      " [[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]] ,  a[:,:].shape = (2, 10)\n",
      "a[1,:] =  [10 11 12 13 14 15 16 17 18 19] ,  a[1,:].shape = (10,) a 1-D array\n",
      "a[1]   =  [10 11 12 13 14 15 16 17 18 19] ,  a[1].shape   = (10,) a 1-D array\n"
     ]
    }
   ],
   "source": [
    "#vector 2-D slicing operations\n",
    "a = np.arange(20).reshape(-1, 10)\n",
    "print(f\"a = \\n{a}\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step)\n",
    "print(\"a[0, 2:7:1] = \", a[0, 2:7:1], \",  a[0, 2:7:1].shape =\", a[0, 2:7:1].shape, \"a 1-D array\")\n",
    "\n",
    "#access 5 consecutive elements (start:stop:step) in two rows\n",
    "print(\"a[:, 2:7:1] = \\n\", a[:, 2:7:1], \",  a[:, 2:7:1].shape =\", a[:, 2:7:1].shape, \"a 2-D array\")\n",
    "\n",
    "# access all elements\n",
    "print(\"a[:,:] = \\n\", a[:,:], \",  a[:,:].shape =\", a[:,:].shape)\n",
    "\n",
    "# access all elements in one row (very common usage)\n",
    "print(\"a[1,:] = \", a[1,:], \",  a[1,:].shape =\", a[1,:].shape, \"a 1-D array\")\n",
    "# same as\n",
    "print(\"a[1]   = \", a[1],   \",  a[1].shape   =\", a[1].shape, \"a 1-D array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bd8b2",
   "metadata": {},
   "source": [
    "# Multiple Variable Linear Regression\n",
    "\n",
    "In this lab, you will extend the data structures and previously developed routines to support multiple features. Several routines are updated making the lab appear lengthy, but it makes minor adjustments to previous routines making it quick to review.\n",
    "# Outline\n",
    "- [1. Problem Statement](#toc_15456_1)\n",
    "- [&nbsp;&nbsp;1.1 Matrix X containing our examples](#toc_15456_1.1)\n",
    "- [&nbsp;&nbsp;1.2 Parameter vector w, b](#toc_15456_1.2)\n",
    "- [2. Model Prediction With Multiple Variables](#toc_15456_2)\n",
    "- [&nbsp;&nbsp;2.1 Single Prediction element by element](#toc_15456_2.1)\n",
    "- [&nbsp;&nbsp;2.2 Single Prediction, vector](#toc_15456_2.2)\n",
    "- [3. Compute Cost With Multiple Variables](#toc_15456_3)\n",
    "- [4. Gradient Descent With Multiple Variables](#toc_15456_4)\n",
    "- [&nbsp;&nbsp;4.1 Compute Gradient with Multiple Variables](#toc_15456_4.1)\n",
    "- [&nbsp;&nbsp;4.2 Gradient Descent With Multiple Variables](#toc_15456_4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe47ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('./deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a510fe",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1\"></a>\n",
    "# 1 Problem Statement\n",
    "\n",
    "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below.  Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.  \n",
    "\n",
    "Please run the following code cell to create your `X_train` and `y_train` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd865da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843320c",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.1\"></a>\n",
    "## 1.1 Matrix X containing our examples\n",
    "Similar to the table above, examples are stored in a NumPy matrix `X_train`. Each row of the matrix represents one example. When you have $m$ training examples ( $m$ is three in our example), and there are $n$ features (four in our example), $\\mathbf{X}$ is a matrix with dimensions ($m$, $n$) (m rows, n columns).\n",
    "\n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "notation:\n",
    "- $\\mathbf{x}^{(i)}$ is vector containing example i. $\\mathbf{x}^{(i)}$ $ = (x^{(i)}_0, x^{(i)}_1, \\cdots,x^{(i)}_{n-1})$\n",
    "- $x^{(i)}_j$ is element j in example i. The superscript in parenthesis indicates the example number while the subscript represents an element.  \n",
    "\n",
    "Display the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a611e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (3, 4), X Type:<class 'numpy.ndarray'>)\n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n",
      "y Shape: (3,), y Type:<class 'numpy.ndarray'>)\n",
      "[460 232 178]\n"
     ]
    }
   ],
   "source": [
    "# data is stored in numpy array/matrix\n",
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c01c3f",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_1.2\"></a>\n",
    "## 1.2 Parameter vector w, b\n",
    "\n",
    "* $\\mathbf{w}$ is a vector with $n$ elements.\n",
    "  - Each element contains the parameter associated with one feature.\n",
    "  - in our dataset, n is 4.\n",
    "  - notionally, we draw this as a column vector\n",
    "\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* $b$ is a scalar parameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35e20c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0715320",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "# 2. Model Prediction With Multiple Variables\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "To demonstrate the dot product, we will implement prediction using (1) and (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854a53a",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.1\"></a>\n",
    "## 2.1 Single Prediction element by element\n",
    "Our previous prediction multiplied one feature value by one parameter and added a bias parameter. A direct extension of our previous implementation of prediction to multiple features would be to implement (1) above using loop over each element, performing the multiply with its parameter and then adding the bias parameter at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd78ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_loop(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters    \n",
    "      b (scalar):  model parameter     \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]  \n",
    "        p = p + p_i         \n",
    "    p = p + b                \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e1f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
      "f_wb shape (), prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106c96c",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2.2\"></a>\n",
    "## 2.2 Single Prediction, vector\n",
    "\n",
    "Noting that equation (1) above can be implemented using the dot product as in (2) above. We can make use of vector operations to speed up predictions.\n",
    "\n",
    "Recall from the Python/Numpy lab that NumPy `np.dot()`[[link](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)] can be used to perform a vector dot product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e0261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b): \n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    p = np.dot(x, w) + b     \n",
    "    return p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6673c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_vec shape (4,), x_vec value: [2104    5    1   45]\n",
      "f_wb shape (), prediction: 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "# get a row from our training data\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "\n",
    "# make a prediction\n",
    "f_wb = predict(x_vec,w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e13fa13",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_3\"></a>\n",
    "# 3. Compute Cost With Multiple Variables\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "In contrast to previous labs, $\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8c0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           #(n,)(n,) = scalar (see np.dot)\n",
    "        cost = cost + (f_wb_i - y[i])**2       #scalar\n",
    "    cost = cost / (2 * m)                      #scalar    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76908080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : 1.5578904428966628e-12\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost using our pre-chosen optimal parameters. \n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c52e9",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "# 4. Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de37873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db (scalar):       The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m,n = X.shape           #(number of examples, number of features)\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5caf63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251501955248e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f73b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn w and b. Updates w and b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb17b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2529.46   \n",
      "Iteration  100: Cost   695.99   \n",
      "Iteration  200: Cost   694.92   \n",
      "Iteration  300: Cost   693.86   \n",
      "Iteration  400: Cost   692.81   \n",
      "Iteration  500: Cost   691.77   \n",
      "Iteration  600: Cost   690.73   \n",
      "Iteration  700: Cost   689.71   \n",
      "Iteration  800: Cost   688.70   \n",
      "Iteration  900: Cost   687.69   \n",
      "b,w found by gradient descent: -0.00,[ 0.2   0.   -0.01 -0.07] \n",
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8398c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(100 + np.arange(len(J_hist[100:])), J_hist[100:])\n",
    "ax1.set_title(\"Cost vs. iteration\");  ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')             ;  ax2.set_ylabel('Cost') \n",
    "ax1.set_xlabel('iteration step')   ;  ax2.set_xlabel('iteration step') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6971f3f5",
   "metadata": {},
   "source": [
    "*These results are not inspiring*! Cost is still declining and our predictions are not very accurate. The next lab will explore how to improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae949f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
